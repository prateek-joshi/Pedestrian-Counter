{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "people-detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOx2i9fTuRJbIBWEfqttVFd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRkg6Odv8Xhg",
        "outputId": "e7fbd288-c7a0-4805-e0b8-c768891bb00f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO0iV0cr-3iD"
      },
      "source": [
        "import os\n",
        "\n",
        "MODEL_NAME = 'Centernet_MobileNet_V2_FPN_512x512'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20210210/centernet_mobilenetv2fpn_512x512_coco17_od.tar.gz'\n",
        "TFRECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLvxW4BG_vSl"
      },
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',MODEL_NAME, 'export'), \n",
        "#     'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "#     'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NfBHt6Q_zZa"
      },
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TFRECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR3-1mX1_3NJ"
      },
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gcst1_sAGnO"
      },
      "source": [
        "# Install tensorflow object-detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m0lS2pF_8I0",
        "outputId": "782ddb93-bf3d-4dbb-f0af-57390cba38cf"
      },
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 57616, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 57616 (delta 13), reused 28 (delta 9), pack-reused 57578\u001b[K\n",
            "Receiving objects: 100% (57616/57616), 572.67 MiB | 28.43 MiB/s, done.\n",
            "Resolving deltas: 100% (39938/39938), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHTGs8FaAQek"
      },
      "source": [
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfjg9HmtAYR9"
      },
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IwAIYGU0Smp"
      },
      "source": [
        "!git clone https://github.com/hai-h-nguyen/Yolo2Pascal-annotation-conversion.git {paths['SCRIPTS_PATH']}\n",
        "!rm -r /content/Tensorflow/scripts/demo /content/Tensorflow/scripts/pascal2yolo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO6_AVibzYf9"
      },
      "source": [
        "# Handle Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6HIiXQpwlVZ"
      },
      "source": [
        "!wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
        "!unzip PennFudanPed.zip -d {paths['IMAGE_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV1e1PVd28qG",
        "outputId": "39ca978d-51be-42e5-a4b0-4ae0f4bf3d84"
      },
      "source": [
        "!pip install pyqt5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyqt5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/62/cd9f10702c75b242f82da858668fba0cda04cda92133244d3d1555e530b4/PyQt5-5.15.4-cp36.cp37.cp38.cp39-abi3-manylinux2014_x86_64.whl (8.3MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3MB 9.3MB/s \n",
            "\u001b[?25hCollecting PyQt5-Qt5>=5.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/d4/241a6a518d0bcf0a9fcdcbad5edfed18d43e884317eab8d5230a2b27e206/PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9MB 44kB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/07/129815a9eac86f67c9b8198d26b4077fe80e261c197a19a245bc81ca3bf6/PyQt5_sip-12.9.0-cp37-cp37m-manylinux1_x86_64.whl (317kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 36.2MB/s \n",
            "\u001b[?25hInstalling collected packages: PyQt5-Qt5, PyQt5-sip, pyqt5\n",
            "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.0 pyqt5-5.15.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwdDVVh1zr_U",
        "outputId": "2c3aaa53-8d63-46ab-8741-edcfc9e075dd"
      },
      "source": [
        "!python {paths['SCRIPTS_PATH']}/yolo2pascal/yolo2voc.py \\\n",
        "  {paths['IMAGE_PATH']}/PennFudanPed/Annotation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convert PennPed00072.txt\n",
            "Load this image: Tensorflow/workspace/images/PennFudanPed/Annotation/PennPed00072.jpg\n",
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/scripts/yolo2pascal/yolo2voc.py\", line 37, in <module>\n",
            "    tYoloParseReader = YoloReader(txtPath, image)\n",
            "  File \"/content/Tensorflow/scripts/yolo2pascal/yolo_io.py\", line 112, in __init__\n",
            "    self.parseYoloFormat()\n",
            "  File \"/content/Tensorflow/scripts/yolo2pascal/yolo_io.py\", line 146, in parseYoloFormat\n",
            "    classIndex, xcen, ycen, w, h = bndBox.split(' ')\n",
            "ValueError: too many values to unpack (expected 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWqn_x8O2ob0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}